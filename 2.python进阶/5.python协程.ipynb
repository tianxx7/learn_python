{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "协程是实现并发编程的一种方式,多线程/多进程,正式解决并发问题的经典模型之一,但是随着互联网的快速发展,遇到了c10k瓶颈,也就是同时连接到服务器的客户达到了一万个,于是很多代码跑崩了,进程上下文切换占用了大量资源,线程也顶不住如此巨大的压力"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "python3.7提供了基于asyncio和async/await的方法\n",
    "\n",
    "**这一节建议在pycharm这类ide中测试,jupyter会有Error**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 一个简单的爬虫例子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crawling url_1\n",
      "OK url_1\n",
      "crawling url_2\n",
      "OK url_2\n",
      "crawling url_3\n",
      "OK url_3\n",
      "crawling url_4\n",
      "OK url_4\n",
      "Wall time: 10 s\n"
     ]
    }
   ],
   "source": [
    "#模拟爬虫\n",
    "import time\n",
    "def crawl_page(url):\n",
    "    print('crawling {}'.format(url))\n",
    "    sleep_time = int(url.split('_')[-1])\n",
    "    time.sleep(sleep_time)\n",
    "    print('OK {}'.format(url))\n",
    "    \n",
    "def main(urls):\n",
    "    for url in urls:\n",
    "        crawl_page(url)\n",
    "        \n",
    "        \n",
    "%time main(['url_1', 'url_2', 'url_3', 'url_4'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**并发化**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crawling url_1\n",
      "OK url_1\n",
      "crawling url_2\n",
      "OK url_2\n",
      "crawling url_3\n",
      "OK url_3\n",
      "crawling url_4\n",
      "OK url_4\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "\n",
    "async def crawl_page(url):\n",
    "    print('crawling {}'.format(url))\n",
    "    sleep_time = int(url.split('_')[-1])\n",
    "    await asyncio.sleep(sleep_time)\n",
    "    print('OK {}'.format(url))\n",
    "    \n",
    "async def main(urls):\n",
    "    for url in urls:\n",
    "        await crawl_page(url)\n",
    "        \n",
    "        \n",
    "#asyncio.run(main(['url_1', 'url_2', 'url_3', 'url_4']))\n",
    "await main(['url_1', 'url_2', 'url_3', 'url_4'])\n",
    "\n",
    "#下面是3.6的写法 建议在colab下运行\n",
    "#loop = asyncio.get_event_loop()\n",
    "#%time loop.run_until_complete(main(['url_1', 'url_2', 'url_3', 'url_4']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "async 修饰词声明异步函数,于是,这里crawl_page和main都变成了异步函数,而调用异步函数,我们便可以得到一个协程对象(coroutine object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<coroutine object async-def-wrapper.<locals>.crawl_page at 0x000001176F90DB48>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program Files\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: RuntimeWarning: coroutine 'async-def-wrapper.<locals>.crawl_page' was never awaited\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    }
   ],
   "source": [
    "print(crawl_page(''))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 执行协程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.await来调用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "await执行的效果,和python正常执行是一样的,也就是说程序会阻塞在这里,进入被调用的协程函数,执行完毕返回后再继续,而这也是await的字面意思<br/>\n",
    "代码中\n",
    "```python\n",
    "await asyncio.sleep(sleep_time)#会在这里休息若干秒,\n",
    "await crawl_page(url)#会执行crawl_page()函数\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.通过asyncio.create_task()来创建任务"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.需要asyncio.run来触发运行"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "asyncio.run这个函数是python3.7之后才有的特性,可以让python的协程接口变得非常简单\n",
    "asyncio.run(main())作为主程序的入口函数\n",
    "在程序运行期间,只调用一次asyncio.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**await是同步调用**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def crawl_page(url):\n",
    "    print('crawling {}'.format(url))\n",
    "    sleep_time = int(url.split('_')[-1])\n",
    "    await asyncio.sleep(sleep_time)\n",
    "    print('OK {}'.format(url))\n",
    "    \n",
    "async def main(urls):\n",
    "    tasks = [asyncio.create_task(crawl_page(url)) for url in urls]\n",
    "    for task in tasks:\n",
    "        await task\n",
    "        \n",
    "#3.6的写法\n",
    "async def main3_6(urls):\n",
    "    tasks = [asyncio.create_task(crawl_page(url)) for url in urls]\n",
    "    for task in tasks:\n",
    "        await task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crawling url_1\n",
      "crawling url_2\n",
      "crawling url_3\n",
      "crawling url_4\n",
      "OK url_1\n",
      "OK url_2\n",
      "OK url_3\n",
      "OK url_4\n"
     ]
    }
   ],
   "source": [
    "#%time asyncio.run(main(['url_1','url_2','url_3','url_4']))\n",
    "await main(['url_1','url_2','url_3','url_4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def count_n(number):\n",
    "    print(\"computer begin\")\n",
    "    n = 0\n",
    "    for i in range(10000):\n",
    "        n += i\n",
    "    print('computer end, loop {} result is {}'.format(number,n))\n",
    "    \n",
    "async def computer_main():\n",
    "    tasks = [asyncio.create_task(count_n(i)) for i in range(3)]\n",
    "    for task in tasks:\n",
    "        await task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computer begin\n",
      "computer end, loop 0 result is 49995000\n",
      "computer begin\n",
      "computer end, loop 1 result is 49995000\n",
      "computer begin\n",
      "computer end, loop 2 result is 49995000\n"
     ]
    }
   ],
   "source": [
    "await computer_main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从这个结果看,如果任务中有休眠,或者阻塞的情况,那么协程将会比较有作用,也就是io密集的话,协程比多线程要简单些"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于task,另一种做法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crawling url_1\n",
      "crawling url_2\n",
      "crawling url_3\n",
      "crawling url_4\n",
      "OK url_1\n",
      "OK url_2\n",
      "OK url_3\n",
      "OK url_4\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    " \n",
    "async def crawl_page(url):\n",
    "    print('crawling {}'.format(url))\n",
    "    sleep_time = int(url.split('_')[-1])\n",
    "    await asyncio.sleep(sleep_time)\n",
    "    print('OK {}'.format(url))\n",
    " \n",
    "async def main(urls):\n",
    "    tasks = [asyncio.create_task(crawl_page(url)) for url in urls]\n",
    "    await asyncio.gather(*tasks)\n",
    "    \n",
    "await main(['url_1', 'url_2', 'url_3', 'url_4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2 3\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "tasks = [1,2,3]\n",
    "def main(arg1, arg2, arg3):\n",
    "    print(arg1)\n",
    "    print(arg2)\n",
    "    print(arg3)\n",
    "\n",
    "print(* tasks)    \n",
    "main(* tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name age\n",
      "txx\n",
      "18\n"
     ]
    }
   ],
   "source": [
    "dic = {\"name\":\"txx\",\"age\":\"18\"}\n",
    "def main(name, age):\n",
    "    print(name)\n",
    "    print(age)\n",
    "print(* dic)\n",
    "main(** dic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*tasks解包列表,将列表变成了函数的参数;与之对应的是,*\\**dict将字典变成函数的参数<br/>\n",
    "asyncio.create_task,asyncio.run这些函数都是py3.7以上版本提供的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before await\n",
      "worker_1 start\n",
      "worker_1 done\n",
      "awaited worker_1\n",
      "worker_2 start\n",
      "worker_2 done\n",
      "awaited worker_2\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    " \n",
    "async def worker_1():\n",
    "    print('worker_1 start')\n",
    "    await asyncio.sleep(1)\n",
    "    print('worker_1 done')\n",
    " \n",
    "async def worker_2():\n",
    "    print('worker_2 start')\n",
    "    await asyncio.sleep(2)\n",
    "    print('worker_2 done')\n",
    " \n",
    "async def main():\n",
    "    print('before await')\n",
    "    await worker_1()\n",
    "    print('awaited worker_1')\n",
    "    await worker_2()\n",
    "    print('awaited worker_2')\n",
    "    \n",
    "\n",
    "#这些都是同步调用\n",
    "await main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before await\n",
      "worker_1 start\n",
      "worker_2 start\n",
      "worker_1 done\n",
      "awaited worker_1\n",
      "worker_2 done\n",
      "awaited worker_2\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    " \n",
    "async def worker_1():\n",
    "    print('worker_1 start')\n",
    "    await asyncio.sleep(1)\n",
    "    print('worker_1 done')\n",
    " \n",
    "async def worker_2():\n",
    "    print('worker_2 start')\n",
    "    await asyncio.sleep(2)\n",
    "    print('worker_2 done')\n",
    " \n",
    "async def main():\n",
    "    task1 = asyncio.create_task(worker_1())\n",
    "    task2 = asyncio.create_task(worker_2())\n",
    "    print('before await')\n",
    "    await task1\n",
    "    print('awaited worker_1')\n",
    "    await task2\n",
    "    print('awaited worker_2')\n",
    " \n",
    "await main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* asyncio.run(main()) 程序进入main()函数,事件循环开启\n",
    "* task1和task2任务被创建,并进入事件循环等待运行,运行到print,输出'before await'\n",
    "* await task1执行,用户选择从当前的主任务中切出,事件调度器开始调度worker_1;\n",
    "* woker_1开始工作,运行 print 输出'worker_1 start'，然后运行到 await asyncio.sleep(1)， 从当前任务切出，事件调度器开始调度 worker_2；\n",
    "* worker_2 开始运行，运行 print 输出 'worker_2 start'，然后运行 await asyncio.sleep(2) 从当前任务切出；\n",
    "* 以上所有事件的运行时间，都应该在 1ms 到 10ms 之间，甚至可能更短，事件调度器从这个时候开始暂停调度；\n",
    "* 一秒钟后，worker_1 的 sleep 完成，事件调度器将控制权重新传给 task_1，输出 'worker_1 done'，task_1 完成任务，从事件循环中退出；\n",
    "* await task1 完成，事件调度器将控制器传给主任务，输出 'awaited worker_1'，·然后在 await task2 处继续等待；\n",
    "* 两秒钟后，worker_2 的 sleep 完成，事件调度器将控制权重新传给 task_2，输出 'worker_2 done'，task_2 完成任务，从事件循环中退出；\n",
    "* 主任务输出 'awaited worker_2'，协程全任务结束，事件循环结束。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 某些协程任务限定时间,一旦超时就取消\n",
    "#### 某些协程运行时出现错误,该怎么处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, ZeroDivisionError('division by zero'), CancelledError()]\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    " \n",
    "async def worker_1():\n",
    "    await asyncio.sleep(1)\n",
    "    return 1\n",
    " \n",
    "async def worker_2():\n",
    "    await asyncio.sleep(2)\n",
    "    return 2 / 0\n",
    " \n",
    "async def worker_3():\n",
    "    await asyncio.sleep(3)\n",
    "    return 3\n",
    " \n",
    "async def main():\n",
    "    task_1 = asyncio.create_task(worker_1())\n",
    "    task_2 = asyncio.create_task(worker_2())\n",
    "    task_3 = asyncio.create_task(worker_3())\n",
    " \n",
    "    await asyncio.sleep(2)\n",
    "    task_3.cancel()\n",
    " \n",
    "    res = await asyncio.gather(task_1, task_2, task_3, return_exceptions=True)\n",
    "    print(res)\n",
    " \n",
    "await main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到worker_1正常工作,worker_2运行中出现错误,worker_3执行时间过长被cancel掉<br/>\n",
    "**注意:** return_exceptions=True这行代码,如果不设置这个参数,错误就会完整地throw到我们这个执行层,从而需要try except来捕捉,这也就意味着其他还没被执行地任务会被全部取消掉,所以需要将return_exceptions设置为True即可"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 协程实现生产者消费者模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "producer_1 put a val: 7\n",
      "producer_2 put a val: 1\n",
      "consumer_1 get a val: 7\n",
      "consumer_2 get a val: 1\n",
      "producer_1 put a val: 7\n",
      "producer_2 put a val: 6\n",
      "consumer_2 get a val: 7\n",
      "consumer_1 get a val: 6\n",
      "producer_1 put a val: 6\n",
      "producer_2 put a val: 9\n",
      "consumer_1 get a val: 6\n",
      "consumer_2 get a val: 9\n",
      "producer_1 put a val: 4\n",
      "producer_2 put a val: 5\n",
      "consumer_2 get a val: 4\n",
      "consumer_1 get a val: 5\n",
      "producer_1 put a val: 3\n",
      "producer_2 put a val: 4\n",
      "consumer_1 get a val: 3\n",
      "consumer_2 get a val: 4\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import random\n",
    " \n",
    "async def consumer(queue, id):\n",
    "    while True:\n",
    "        val = await queue.get()\n",
    "        print('{} get a val: {}'.format(id, val))\n",
    "        await asyncio.sleep(1)\n",
    " \n",
    "async def producer(queue, id):\n",
    "    for i in range(5):\n",
    "        val = random.randint(1, 10)\n",
    "        await queue.put(val)\n",
    "        print('{} put a val: {}'.format(id, val))\n",
    "        await asyncio.sleep(1)\n",
    " \n",
    "async def main():\n",
    "    queue = asyncio.Queue()\n",
    " \n",
    "    consumer_1 = asyncio.create_task(consumer(queue, 'consumer_1'))\n",
    "    consumer_2 = asyncio.create_task(consumer(queue, 'consumer_2'))\n",
    " \n",
    "    producer_1 = asyncio.create_task(producer(queue, 'producer_1'))\n",
    "    producer_2 = asyncio.create_task(producer(queue, 'producer_2'))\n",
    " \n",
    "    await asyncio.sleep(10)\n",
    "    consumer_1.cancel()\n",
    "    consumer_2.cancel()\n",
    "    \n",
    "    await asyncio.gather(consumer_1, consumer_2, producer_1, producer_2, return_exceptions=True)\n",
    " \n",
    "await main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: aiohttp in d:\\program files\\anaconda3\\lib\\site-packages (3.6.2)\n",
      "Requirement already satisfied: async-timeout<4.0,>=3.0 in d:\\program files\\anaconda3\\lib\\site-packages (from aiohttp) (3.0.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in d:\\program files\\anaconda3\\lib\\site-packages (from aiohttp) (1.4.2)\n",
      "Requirement already satisfied: multidict<5.0,>=4.5 in d:\\program files\\anaconda3\\lib\\site-packages (from aiohttp) (4.7.5)\n",
      "Requirement already satisfied: attrs>=17.3.0 in d:\\program files\\anaconda3\\lib\\site-packages (from aiohttp) (19.2.0)\n",
      "Requirement already satisfied: chardet<4.0,>=2.0 in d:\\program files\\anaconda3\\lib\\site-packages (from aiohttp) (3.0.4)\n",
      "Requirement already satisfied: idna>=2.0 in d:\\program files\\anaconda3\\lib\\site-packages (from yarl<2.0,>=1.0->aiohttp) (2.8)\n"
     ]
    }
   ],
   "source": [
    "!pip install aiohttp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: bs4 in d:\\program files\\anaconda3\\lib\\site-packages (0.0.1)\n",
      "Requirement already satisfied: beautifulsoup4 in d:\\program files\\anaconda3\\lib\\site-packages (from bs4) (4.8.0)\n",
      "Requirement already satisfied: soupsieve>=1.2 in d:\\program files\\anaconda3\\lib\\site-packages (from beautifulsoup4->bs4) (1.9.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "金禅降魔 05月08日 https://img9.doubanio.com/view/photo/s_ratio_poster/public/p2564190636.jpg\n",
      "82号古宅 05月15日 https://img3.doubanio.com/view/photo/s_ratio_poster/public/p2586838530.jpg\n",
      "亲亲哒 05月28日 https://img9.doubanio.com/view/photo/s_ratio_poster/public/p2579189776.jpg\n",
      "奇妙王国之魔法奇缘 06月01日 https://img3.doubanio.com/view/photo/s_ratio_poster/public/p2577837112.jpg\n",
      "六月的秘密 06月21日 https://img1.doubanio.com/view/photo/s_ratio_poster/public/p2522497098.jpg\n",
      "秘密访客 06月25日 https://img1.doubanio.com/view/photo/s_ratio_poster/public/p2579398648.jpg\n",
      "无名狂 06月25日 https://img3.doubanio.com/view/photo/s_ratio_poster/public/p2574800433.jpg\n",
      "我想静静 08月07日 https://img1.doubanio.com/view/photo/s_ratio_poster/public/p2595969179.jpg\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import aiohttp\n",
    " \n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "header = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/81.0.4044.129 Safari/537.36'}\n",
    " \n",
    "async def fetch_content(url):\n",
    "    async with aiohttp.ClientSession(\n",
    "        headers=header, connector=aiohttp.TCPConnector(ssl=False)\n",
    "    ) as session:\n",
    "        async with session.get(url) as response:\n",
    "            return await response.text()\n",
    " \n",
    "async def main():\n",
    "    url = \"https://movie.douban.com/cinema/later/beijing/\"\n",
    "    init_page = await fetch_content(url)\n",
    "    init_soup = BeautifulSoup(init_page, 'lxml')\n",
    " \n",
    "    movie_names, urls_to_fetch, movie_dates = [], [], []\n",
    " \n",
    "    all_movies = init_soup.find('div', id=\"showing-soon\")\n",
    "    for each_movie in all_movies.find_all('div', class_=\"item\"):\n",
    "        all_a_tag = each_movie.find_all('a')\n",
    "        all_li_tag = each_movie.find_all('li')\n",
    " \n",
    "        movie_names.append(all_a_tag[1].text)\n",
    "        urls_to_fetch.append(all_a_tag[1]['href'])\n",
    "        movie_dates.append(all_li_tag[0].text)\n",
    " \n",
    "    tasks = [fetch_content(url) for url in urls_to_fetch]\n",
    "    pages = await asyncio.gather(*tasks)\n",
    " \n",
    "    for movie_name, movie_date, page in zip(movie_names, movie_dates, pages):\n",
    "        soup_item = BeautifulSoup(page, 'lxml')\n",
    "        img_tag = soup_item.find('img')\n",
    " \n",
    "        print('{} {} {}'.format(movie_name, movie_date, img_tag['src']))\n",
    " \n",
    "await main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
